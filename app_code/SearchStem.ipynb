{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "406fd679-3dda-427c-b1db-0a50e3ef5fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Импорт библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b4eb12b-a802-47c5-894c-d01bc212af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Загрузка данных и индекса\n",
    "df = pd.read_csv('../shared_data/news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05d056be-5301-4c52-b927-44398fb81b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выберите нужный индекс (стеммированный или лемматизированный)\n",
    "INDEX_FILE = '../shared_data/search_index.pkl'  # стеммированный\n",
    "#INDEX_FILE = '../shared_data/lemmatized_search_index.pkl'  # лемматизированный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4d76386-48f9-4b06-8558-0614a5465689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка индекса...\n"
     ]
    }
   ],
   "source": [
    "print(\"Загрузка индекса...\")\n",
    "with open(INDEX_FILE, 'rb') as f:\n",
    "    index_data = pickle.load(f)\n",
    "\n",
    "inverted_index = index_data['inverted_index']\n",
    "doc_lengths = index_data['doc_lengths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d742e9a0-8031-478e-93d0-f2ed4af85504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Класс поисковой системы\n",
    "class VectorSearchEngine:\n",
    "    def __init__(self, inverted_index, doc_lengths, total_docs):\n",
    "        self.inverted_index = inverted_index\n",
    "        self.doc_lengths = doc_lengths\n",
    "        self.total_docs = total_docs\n",
    "        self.idf_cache = {}\n",
    "        self.doc_norms = {}\n",
    "        \n",
    "        # Предварительно вычисляем IDF для всех терминов\n",
    "        self._precompute_idf()\n",
    "        # Предварительно вычисляем нормы документов\n",
    "        self._precompute_doc_norms()\n",
    "    \n",
    "    def _precompute_idf(self):\n",
    "        \"\"\"Предварительное вычисление IDF для всех терминов в индексе\"\"\"\n",
    "        print(\"Вычисление IDF...\")\n",
    "        for term, doc_freqs in self.inverted_index.items():\n",
    "            df_t = len(doc_freqs)  # количество документов с термином\n",
    "            self.idf_cache[term] = math.log(self.total_docs / (1 + df_t))\n",
    "    \n",
    "    def _precompute_doc_norms(self):\n",
    "        \"\"\"Предварительное вычисление норм документов для косинусного сходства\"\"\"\n",
    "        print(\"Вычисление норм документов...\")\n",
    "        # Инициализируем нулями\n",
    "        doc_vectors = defaultdict(lambda: defaultdict(float))\n",
    "        \n",
    "        # Собираем TF-IDF векторы\n",
    "        for term, doc_freqs in self.inverted_index.items():\n",
    "            idf = self.idf_cache[term]\n",
    "            for doc_id, freq in doc_freqs.items():\n",
    "                if doc_id in self.doc_lengths and self.doc_lengths[doc_id] > 0:\n",
    "                    tf = freq / self.doc_lengths[doc_id]\n",
    "                    tf_idf = tf * idf\n",
    "                    doc_vectors[doc_id][term] = tf_idf\n",
    "        \n",
    "        # Вычисляем нормы (длины векторов)\n",
    "        for doc_id, vector in doc_vectors.items():\n",
    "            self.doc_norms[doc_id] = math.sqrt(sum(tf_idf ** 2 for tf_idf in vector.values()))\n",
    "    \n",
    "    def _compute_query_vector(self, query_terms):\n",
    "        \"\"\"Вычисление TF-IDF вектора для запроса\"\"\"\n",
    "        query_tf = defaultdict(int)\n",
    "        for term in query_terms:\n",
    "            query_tf[term] += 1\n",
    "        \n",
    "        query_vector = {}\n",
    "        query_length = len(query_terms)\n",
    "        \n",
    "        for term, freq in query_tf.items():\n",
    "            if term in self.idf_cache:\n",
    "                tf = freq / query_length\n",
    "                idf = self.idf_cache[term]\n",
    "                query_vector[term] = tf * idf\n",
    "        \n",
    "        # Вычисляем норму запроса\n",
    "        query_norm = math.sqrt(sum(tf_idf ** 2 for tf_idf in query_vector.values()))\n",
    "        \n",
    "        return query_vector, query_norm\n",
    "    \n",
    "    def search(self, query, preprocess_func, top_k=10):\n",
    "        \"\"\"\n",
    "        Поиск релевантных документов по запросу\n",
    "        \n",
    "        Args:\n",
    "            query: поисковый запрос\n",
    "            preprocess_func: функция предобработки (стемминг или лемматизация)\n",
    "            top_k: количество возвращаемых результатов\n",
    "        \"\"\"\n",
    "        # Предобработка запроса\n",
    "        query_terms = preprocess_func(query)\n",
    "        print(f\"Обработанный запрос: {query_terms}\")\n",
    "        \n",
    "        if not query_terms:\n",
    "            return []\n",
    "        \n",
    "        # Вычисляем вектор запроса\n",
    "        query_vector, query_norm = self._compute_query_vector(query_terms)\n",
    "        \n",
    "        if not query_vector:\n",
    "            return []\n",
    "        \n",
    "        # Вычисляем релевантность для каждого документа\n",
    "        scores = defaultdict(float)\n",
    "        \n",
    "        for term, query_tf_idf in query_vector.items():\n",
    "            if term in self.inverted_index:\n",
    "                for doc_id, freq in self.inverted_index[term].items():\n",
    "                    if doc_id not in self.doc_norms:\n",
    "                        continue\n",
    "                    \n",
    "                    # Вычисляем TF-IDF для термина в документе\n",
    "                    if self.doc_lengths[doc_id] > 0:\n",
    "                        tf = freq / self.doc_lengths[doc_id]\n",
    "                        doc_tf_idf = tf * self.idf_cache[term]\n",
    "                        \n",
    "                        # Косинусное сходство: dot product / (norm_q * norm_d)\n",
    "                        scores[doc_id] += query_tf_idf * doc_tf_idf\n",
    "        \n",
    "        # Нормализуем по косинусному сходству\n",
    "        for doc_id in scores:\n",
    "            if self.doc_norms[doc_id] > 0 and query_norm > 0:\n",
    "                scores[doc_id] /= (query_norm * self.doc_norms[doc_id])\n",
    "        \n",
    "        # Сортируем по убыванию релевантности\n",
    "        sorted_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "        \n",
    "        return sorted_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98cc3a5b-22ab-412d-98e3-be53dd4abd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Функции предобработки (должны быть такими же, как при построении индекса)\n",
    "def get_preprocessing_function(index_type='stemmed'):\n",
    "    \"\"\"\n",
    "    Возвращает функцию предобработки в зависимости от типа индекса\n",
    "    \"\"\"\n",
    "    if index_type == 'lemmatized':\n",
    "        # Импортируем и используем лемматизацию\n",
    "        import pymorphy3\n",
    "        from nltk.corpus import stopwords\n",
    "        import re\n",
    "        \n",
    "        morph = pymorphy3.MorphAnalyzer()\n",
    "        russian_stopwords = set(stopwords.words('russian'))\n",
    "        \n",
    "        def preprocess_lemmatized(text):\n",
    "            if pd.isna(text):\n",
    "                return []\n",
    "            text = re.sub(r'[^a-zA-Zа-яА-ЯёЁ\\s]', ' ', str(text))\n",
    "            text = text.lower()\n",
    "            tokens = text.split()\n",
    "            processed_tokens = []\n",
    "            for token in tokens:\n",
    "                if token not in russian_stopwords and len(token) > 2:\n",
    "                    lemma = morph.parse(token)[0].normal_form\n",
    "                    if len(lemma) > 2:\n",
    "                        processed_tokens.append(lemma)\n",
    "            return processed_tokens\n",
    "        \n",
    "        return preprocess_lemmatized\n",
    "    \n",
    "    else:\n",
    "        # Используем стемминг (по умолчанию)\n",
    "        from nltk.stem import SnowballStemmer\n",
    "        from nltk.corpus import stopwords\n",
    "        import re\n",
    "        \n",
    "        stemmer = SnowballStemmer(\"russian\")\n",
    "        russian_stopwords = set(stopwords.words('russian'))\n",
    "        \n",
    "        def preprocess_stemmed(text):\n",
    "            if pd.isna(text):\n",
    "                return []\n",
    "            text = re.sub(r'[^a-zA-Zа-яА-ЯёЁ\\s]', ' ', str(text))\n",
    "            text = text.lower()\n",
    "            tokens = text.split()\n",
    "            processed_tokens = []\n",
    "            for token in tokens:\n",
    "                if token not in russian_stopwords and len(token) > 2:\n",
    "                    stem = stemmer.stem(token)\n",
    "                    processed_tokens.append(stem)\n",
    "            return processed_tokens\n",
    "        \n",
    "        return preprocess_stemmed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e489e739-6ca0-4b47-afb8-c3a364cd782c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Инициализация поисковой системы...\n",
      "Вычисление IDF...\n",
      "Вычисление норм документов...\n"
     ]
    }
   ],
   "source": [
    "# 5. Инициализация поисковой системы\n",
    "print(\"Инициализация поисковой системы...\")\n",
    "total_docs = len(df)\n",
    "search_engine = VectorSearchEngine(inverted_index, doc_lengths, total_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a575e183-d8db-4a10-a6b6-e8dc5ba712ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется стеммированный индекс\n"
     ]
    }
   ],
   "source": [
    "# Определяем тип предобработки на основе используемого индекса\n",
    "if 'lemmatized' in INDEX_FILE:\n",
    "    preprocess_func = get_preprocessing_function('lemmatized')\n",
    "    print(\"Используется лемматизированный индекс\")\n",
    "else:\n",
    "    preprocess_func = get_preprocessing_function('stemmed')\n",
    "    print(\"Используется стеммированный индекс\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7ed94b3-2faa-4d27-9525-8649f3bb9cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Функция для красивого вывода результатов\n",
    "def display_results(search_results, df, query):\n",
    "    \"\"\"Красивый вывод результатов поиска\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"РЕЗУЛЬТАТЫ ПОИСКА: '{query}'\")\n",
    "    print(f\"Найдено документов: {len(search_results)}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for i, (doc_id, score) in enumerate(search_results, 1):\n",
    "        if doc_id < len(df):\n",
    "            title = df.iloc[doc_id]['title']\n",
    "            source = df.iloc[doc_id]['source']\n",
    "            rubric = df.iloc[doc_id]['rubric']\n",
    "            text_preview = df.iloc[doc_id]['text'][:300] + \"...\"\n",
    "            \n",
    "            print(f\"\\n#{i} (релевантность: {score:.4f})\")\n",
    "            print(f\"Заголовок: {title}\")\n",
    "            print(f\"Источник: {source} | Рубрика: {rubric}\")\n",
    "            print(f\"Текст: {text_preview}\")\n",
    "            print(f\"{'-'*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a59bd0e3-6db1-4efd-ac2e-189d5a403d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Интерактивный поиск\n",
    "def interactive_search():\n",
    "    \"\"\"Интерактивный режим поиска\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ИНТЕРАКТИВНЫЙ ПОИСК НОВОСТЕЙ\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Доступные команды:\")\n",
    "    print(\"  - Введите поисковый запрос для поиска\")\n",
    "    print(\"  - 'quit' или 'exit' для выхода\")\n",
    "    print(\"  - 'top N' для изменения количества результатов (по умолчанию 10)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    top_k = 10\n",
    "    \n",
    "    while True:\n",
    "        query = input(\"\\nВведите поисковый запрос: \").strip()\n",
    "        \n",
    "        if query.lower() in ['quit', 'exit', 'выход']:\n",
    "            print(\"Завершение работы поисковой системы...\")\n",
    "            break\n",
    "        \n",
    "        elif query.lower().startswith('top '):\n",
    "            try:\n",
    "                new_top = int(query.split()[1])\n",
    "                if new_top > 0:\n",
    "                    top_k = new_top\n",
    "                    print(f\"Количество результатов изменено на: {top_k}\")\n",
    "                else:\n",
    "                    print(\"Количество результатов должно быть положительным числом\")\n",
    "            except:\n",
    "                print(\"Использование: 'top N' где N - целое число\")\n",
    "            continue\n",
    "        \n",
    "        elif query:\n",
    "            print(f\"\\nПоиск: '{query}'...\")\n",
    "            results = search_engine.search(query, preprocess_func, top_k=top_k)\n",
    "            display_results(results, df, query)\n",
    "        \n",
    "        else:\n",
    "            print(\"Введите непустой запрос\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c109b0a-252e-4d60-83fc-4a52f16a01b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Тестовые запросы для демонстрации\n",
    "def test_queries():\n",
    "    \"\"\"Тестовые запросы для проверки работы системы\"\"\"\n",
    "    test_cases = [\n",
    "        \"олимпийская чемпионка Загитова\",\n",
    "        \"экономика России\",\n",
    "        \"Москва новости\",\n",
    "        \"технологии искусственный интеллект\",\n",
    "        \"спортивные соревнования\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ТЕСТОВЫЕ ЗАПРОСЫ\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for query in test_cases:\n",
    "        print(f\"\\nТестовый запрос: '{query}'\")\n",
    "        results = search_engine.search(query, preprocess_func, top_k=3)\n",
    "        display_results(results, df, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32c1923c-173d-4e90-befc-a3831dfabf90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ТЕСТОВЫЕ ЗАПРОСЫ\n",
      "==================================================\n",
      "\n",
      "Тестовый запрос: 'олимпийская чемпионка Загитова'\n",
      "Обработанный запрос: ['олимпийск', 'чемпионк', 'загитов']\n",
      "\n",
      "================================================================================\n",
      "РЕЗУЛЬТАТЫ ПОИСКА: 'олимпийская чемпионка Загитова'\n",
      "Найдено документов: 3\n",
      "================================================================================\n",
      "\n",
      "#1 (релевантность: 0.6256)\n",
      "Заголовок: Загитова согласилась вести «Ледниковый период»\n",
      "Источник: lenta.ru | Рубрика: Спорт\n",
      "Текст: Олимпийская чемпионка по фигурному катанию  Алина Загитова  согласилась стать ведущей шоу «Ледниковый период». Об этом сообщает Sport24. Переговоры с фигуристкой осложнялись из-за того, что Загитова изначально не была готова сосредоточиться на телевидении и временно отказаться от выступлений. После ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "#2 (релевантность: 0.5786)\n",
      "Заголовок: Загитова похвасталась водительскими правами через два дня после совершеннолетия\n",
      "Источник: lenta.ru | Рубрика: Спорт\n",
      "Текст: Олимпийская чемпионка по фигурному катанию  Алина Загитова  сообщила о получении водительского удостоверения. Об этом спортсменка рассказала на своей странице в  Instagram . Россиянка отметила, что очень нервничала, но сумела справиться с волнением. По словам фигуристки, правила дорожного движения о...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "#3 (релевантность: 0.5375)\n",
      "Заголовок: Заработки Загитовой и Медведевой посчитали недостаточными\n",
      "Источник: lenta.ru | Рубрика: Спорт\n",
      "Текст: Двукратный олимпийский чемпион  Евгений Плющенко  посчитал, что российские фигуристки  Алина Загитова  и  Евгения Медведева  могли бы зарабатывать больше при грамотном менеджменте. Об этом он рассказал в интервью «Спорт-Экспрессу». «Понимаю, что эти суммы, которые они получают, для многих большие, н...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Тестовый запрос: 'экономика России'\n",
      "Обработанный запрос: ['экономик', 'росс']\n",
      "\n",
      "================================================================================\n",
      "РЕЗУЛЬТАТЫ ПОИСКА: 'экономика России'\n",
      "Найдено документов: 3\n",
      "================================================================================\n",
      "\n",
      "#1 (релевантность: 0.3892)\n",
      "Заголовок: В Кремле призвали не «морозить» экономику в российских регионах\n",
      "Источник: lenta.ru | Рубрика: Экономика\n",
      "Текст: В российских регионах, где пока наблюдается благоприятная ситуация с распространением коронавируса, не стоит «морозить» экономику. Об этом заявил пресс-секретарь президента России  Дмитрий Песков  в эфире «Москва. Кремль. Путин», передает  РИА Новости . По словам представителя Кремля, в России есть ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "#2 (релевантность: 0.3638)\n",
      "Заголовок: Эксперт: мировая экономика замедлилась бы и без вспышки коронавируса\n",
      "Источник: ria.ru | Рубрика: nan\n",
      "Текст: МОСКВА, 29 фев - РИА Новости.  Мировая экономика в 2020 году могла бы замедлиться и без  коронавируса  на фоне окончания циклического роста, негатив от распространения вирусной инфекции лишь ускорил течение событий, сказал РИА Новости директор по анализу финансовых рынков и макроэкономики УК \"Альфа-...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "#3 (релевантность: 0.3404)\n",
      "Заголовок: ВЭФ спрогнозировал снижение роста экономики России из-за цен на нефть\n",
      "Источник: ria.ru | Рубрика: nan\n",
      "Текст: ЖЕНЕВА, 2 апр —   РИА Новости, Елизавета Исакова.  Низкие цены и падение мирового спроса на нефть снизят рост российской экономики, заявил РИА Новости ведущий экономист Всемирного экономического форума (ВЭФ) Роберто Кротти. \"Что касается России, то пока что вспышка  COVID-19  кажется там менее тяжел...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Тестовый запрос: 'Москва новости'\n",
      "Обработанный запрос: ['москв', 'новост']\n",
      "\n",
      "================================================================================\n",
      "РЕЗУЛЬТАТЫ ПОИСКА: 'Москва новости'\n",
      "Найдено документов: 3\n",
      "================================================================================\n",
      "\n",
      "#1 (релевантность: 0.2128)\n",
      "Заголовок: Опубликован полный список рейсов в Россию с зараженными коронавирусом\n",
      "Источник: lenta.ru | Рубрика: Путешествия\n",
      "Текст: Опубликован полный список рейсов в Россию с зараженными коронавирусом пассажирами. Он приводится в  Telegram -канале «Коронавирус. Оперштаб Москвы». Это рейсы SU 2613 Милан — Москва (20 февраля); SU 2322 Москва — Мюнхен (22 февраля); 9U 175 Кишинев — Москва (24 февраля); SU 2323 Мюнхен — Москва, SU ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "#2 (релевантность: 0.1452)\n",
      "Заголовок: Число умерших пациентов с коронавирусом в Москве превысило 100 человек\n",
      "Источник: ria.ru | Рубрика: nan\n",
      "Текст: МОСКВА, 15 апр - РИА Новости.  Число умерших пациентов с  коронавирусом  в  Москве  достигло 106 человек, следует из данных оперативного штаба. Согласно данным на 14 апреля, в Москве было 95 умерших пациентов с коронавирусом. \"В Москве скончались 11 пациентов с подтвержденной пневмонией и положитель...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "#3 (релевантность: 0.1450)\n",
      "Заголовок: В Москве зафиксировали 695 новых случаев заражения коронавирусом\n",
      "Источник: ria.ru | Рубрика: nan\n",
      "Текст: МОСКВА, 30 авг - РИА Новости.  Наибольшее число новых случаев COVID-19 в  Москве  — 695,  Санкт-Петербурге  — 186,  Подмосковье  — 165, сообщили журналистам в оперативном штабе по борьбе с распространением коронавирусной инфекции. \"Распределение по субъектам: 1. Москва - 695, 2. Санкт-Петербург - 18...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Тестовый запрос: 'технологии искусственный интеллект'\n",
      "Обработанный запрос: ['технолог', 'искусствен', 'интеллект']\n",
      "\n",
      "================================================================================\n",
      "РЕЗУЛЬТАТЫ ПОИСКА: 'технологии искусственный интеллект'\n",
      "Найдено документов: 3\n",
      "================================================================================\n",
      "\n",
      "#1 (релевантность: 0.6472)\n",
      "Заголовок: Роботы и искусственный интеллект будут отвечать за причиненный вред\n",
      "Источник: ria.ru | Рубрика: nan\n",
      "Текст: МОСКВА, 21 фев - РИА Новости.   Минэкономразвития РФ  и  Сбербанк  к 8 декабря 2021 года разработают правила ответственности за причиненный роботами и  искусственным интеллектом  (ИИ) вред и правила страхования таких рисков, следует из проекта дорожной карты развития искусственного интеллекта в Росс...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "#2 (релевантность: 0.5917)\n",
      "Заголовок: Пентагон принял этические принципы для искусственного интеллекта\n",
      "Источник: ria.ru | Рубрика: nan\n",
      "Текст: ВАШИНГТОН, 25 фев —   РИА Новости, Алексей Богдановский.   Пентагон  сообщил, что официально принял этические принципы использования искусственного интеллекта в вооружениях. Рекомендации передали министру обороны  Марку Эсперу  осенью 2019 года после 15-месячного периода выработки этики боевых машин...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "#3 (релевантность: 0.3396)\n",
      "Заголовок: Тюменская нейросеть запишет в МФЦ и поможет врачам обследовать пациентов\n",
      "Источник: ria.ru | Рубрика: nan\n",
      "Текст: МОСКВА, 21 авг — РИА Новости.   Жители Тюменской области могут получить консультацию по государственным и муниципальным услугам и записаться в МФЦ в любое время суток, без выходных и праздничных дней, используя искусственный интеллект. Благодаря внедрению новой диалоговой нейросетевой системы больше...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Тестовый запрос: 'спортивные соревнования'\n",
      "Обработанный запрос: ['спортивн', 'соревнован']\n",
      "\n",
      "================================================================================\n",
      "РЕЗУЛЬТАТЫ ПОИСКА: 'спортивные соревнования'\n",
      "Найдено документов: 3\n",
      "================================================================================\n",
      "\n",
      "#1 (релевантность: 0.2996)\n",
      "Заголовок: Программирование — это спорт\n",
      "Источник: meduza.io | Рубрика: nan\n",
      "Текст: При слове «программист» обычно в голове возникает образ сотрудника какой-нибудь технологической корпорации, который целыми днями пишет длинный код для сложной программы. Многие программисты действительно этим и занимаются. Но есть и другие — спортивные программисты. Вместе с  Университетом ИТМО  рас...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "#2 (релевантность: 0.2798)\n",
      "Заголовок: Чемпионат мира по фигурному катанию отменили из-за коронавируса\n",
      "Источник: lenta.ru | Рубрика: Спорт\n",
      "Текст: Чемпионат мира по фигурному катанию в Канаде отменили из-за вспышки коронавирусной инфекции по всему миру. Об этом сообщается в  Twitter -аккаунте телеканала CBC. Соревнования должны были пройти с 16 по 22 марта в Монреале. В течение ближайших недель в Международном союзе конькобежцев (ISU) обсудят ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "#3 (релевантность: 0.2521)\n",
      "Заголовок: В России иностранцам запретили посещать музеи и театры\n",
      "Источник: meduza.io | Рубрика: nan\n",
      "Текст: Минкульт РФ рекомендовал подведомственным учреждениям временно ввести запрет на посещение для иностранцев, сообщает «Интерфакс». Также Минкульт поручил  закрыть  для посещения библиотеки, ограничить проведение массовых мероприятий (в том числе экскурсий) в музеях и остановить заграничные гастроли тв...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2727fbc-5080-41f1-90f6-8492fdc96c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
